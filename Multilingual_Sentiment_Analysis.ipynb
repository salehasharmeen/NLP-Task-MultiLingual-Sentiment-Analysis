{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salehasharmeen/NLP-Task-MultiLingual-Sentiment-Analysis/blob/main/Multilingual_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f05obQRs233i"
      },
      "outputs": [],
      "source": [
        "#Step 1: Install Required Libraries\n",
        "!pip install transformers datasets accelerate evaluate streamlit pyngrok pandas torch -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fEilrx-Kgcr",
        "outputId": "26136110-e865-4b1e-d88d-eddb59c080af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Import Libraries and Set Up Environment\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6KkLRrCK2_p",
        "outputId": "46631ab1-e489-4557-d2a7-acdd9ce8fdf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared. Train/Test split created.\n",
            "Training examples: 8000\n",
            "Testing examples: 2000\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Loading and preparing dataset\n",
        "\n",
        "print(\"Loading and preparing dataset...\")\n",
        "\n",
        "# Load the 'amazon_polarity' dataset from the Hugging Face Hub\n",
        "# This dataset is a stable and reliable alternative for binary sentiment analysis.\n",
        "dataset = load_dataset(\"amazon_polarity\", split=\"train[:10000]\")\n",
        "\n",
        "# 'amazon_polarity' already has a 'label' column (1=positive, 0=negative), so\n",
        "# we don't need the custom mapping function. We just need to rename the\n",
        "# 'content' column to 'review_body' for consistency.\n",
        "dataset = dataset.rename_column(\"content\", \"review_body\")\n",
        "\n",
        "# The original dataset had a split, so we'll create one here for consistency.\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "print(\"Dataset prepared. Train/Test split created.\")\n",
        "print(f\"Training examples: {len(dataset['train'])}\")\n",
        "print(f\"Testing examples: {len(dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a490f1a39b144a5bad4538dae59bc050",
            "8378e54cbf2b4e25b07fe5d6913396d3",
            "18b8d84f9fc646d1a6dc338c6a40033f",
            "caee5f82c70644768def53fa6c97ef83",
            "fd864a7710874f82b7457cdf6bc3fd07",
            "545c48a0ac234db18f4e3d2d13ee3851",
            "f44a6aa3ec5b4086b1e169011e8f8408",
            "030c58f182cd4c489ed764ebf167cd14",
            "60e994e8658343ba8b42fccf9fd1bf8e",
            "a5e40615d5aa4c5da93ccb6ba5260e98",
            "d20f3d25d2f24e908f0e2407705a062d"
          ]
        },
        "id": "cwqiWjilMgr4",
        "outputId": "73f2d2c4-5207-45cb-d1db-a74dbae15bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer and tokenizing data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a490f1a39b144a5bad4538dae59bc050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Tokenization\n",
        "print(\"Loading tokenizer and tokenizing data...\")\n",
        "\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['review_body'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove original columns not needed for training\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"title\", \"review_body\"])\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "print(\"Tokenization complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGeG7d-MMuBo",
        "outputId": "daecb5ec-8623-4ca0-930f-74be105e16c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model and setting up training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Load Model and Define Training Arguments\n",
        "print(\"Loading model and setting up training...\")\n",
        "\n",
        "num_labels = 2 # Negative, Positive\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "model.to(device)\n",
        "\n",
        "# Define evaluation metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\", # Disable reporting to Hugging Face Hub\n",
        ")\n",
        "\n",
        "# Create the Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "-9jMoTpIR3Zc",
        "outputId": "52740e6f-0c75-4410-b890-f14e9496646f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 12:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.399100</td>\n",
              "      <td>0.370260</td>\n",
              "      <td>0.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.223800</td>\n",
              "      <td>0.344287</td>\n",
              "      <td>0.873500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.128500</td>\n",
              "      <td>0.473119</td>\n",
              "      <td>0.881000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n",
            "Model and tokenizer saved to disk.\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Fine-tune the Model\n",
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "model_path = \"./fine-tuned-model\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(\"Model and tokenizer saved to disk.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6b: Save the Model to Google Drive\n",
        "#\n",
        "# Run this cell once after Step 6 to save your fine-tuned model\n",
        "# to a permanent location for later use.\n",
        "# ==============================================================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to save the model on your Drive\n",
        "drive_path = \"/content/drive/My Drive/sentiment_model\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer to Google Drive\n",
        "trainer.save_model(drive_path)\n",
        "tokenizer.save_pretrained(drive_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to Google Drive at: {drive_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTTT6R4zr-m7",
        "outputId": "0e17bf09-0ed3-470f-9a44-bf4491867186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model and tokenizer saved to Google Drive at: /content/drive/My Drive/sentiment_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the Fine-Tuned Model\n",
        "print(\"Starting model evaluation...\")\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Model evaluation complete.\")\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"\\n=== Model Evaluation Results ===\")\n",
        "for key, value in evaluation_results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"\\nEvaluation complete. The model is ready for inference.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "bBpO-an9v2s-",
        "outputId": "4d8d5cad-e27f-41d0-e49c-b269a1786a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model evaluation complete.\n",
            "\n",
            "=== Model Evaluation Results ===\n",
            "eval_loss: 0.34428706765174866\n",
            "eval_accuracy: 0.8735\n",
            "eval_runtime: 13.6144\n",
            "eval_samples_per_second: 146.904\n",
            "eval_steps_per_second: 9.181\n",
            "epoch: 3.0\n",
            "\n",
            "Evaluation complete. The model is ready for inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Streamlit App\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import os\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to load model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    \"\"\"\n",
        "    Loads the fine-tuned model and tokenizer from the saved directory.\n",
        "    This function is cached to prevent reloading the model on every interaction.\n",
        "    \"\"\"\n",
        "    model_path = \"./fine-tuned-model\"\n",
        "    if not os.path.exists(model_path):\n",
        "        st.error(f\"Error: The model directory '{model_path}' was not found. Please make sure you have run the training step (Step 6) to fine-tune and save the model.\")\n",
        "        return None, None\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        model.to(device)\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# Set up the Streamlit app\n",
        "st.set_page_config(page_title=\"Multilingual Sentiment Analysis\", layout=\"wide\")\n",
        "st.title(\"🌎 Multilingual Sentiment Analysis\")\n",
        "st.markdown(\"Enter a product review in a language like English, Spanish, or French and get the sentiment prediction.\")\n",
        "\n",
        "# Text input for the user\n",
        "user_input = st.text_area(\"Enter review text here:\", height=200, placeholder=\"e.g., This product is amazing!\")\n",
        "\n",
        "if st.button(\"Analyze Sentiment\"):\n",
        "    if user_input and tokenizer and model:\n",
        "        # Define labels for the output\n",
        "        labels = [\"Negative\", \"Positive\"] # Updated labels for the new dataset\n",
        "\n",
        "        # Tokenize the user input\n",
        "        inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            with torch.no_grad():\n",
        "                # Get the model's predictions\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "                probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "                predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "        # Display the results\n",
        "        st.subheader(\"Results\")\n",
        "        st.success(f\"**Predicted Sentiment:** {labels[predicted_class_id]}\")\n",
        "        st.info(f\"**Confidence:** {probabilities[0][predicted_class_id].item():.2f}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter some text to analyze and ensure the model is loaded correctly.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEt0197ZWZif",
        "outputId": "b95817e7-5455-4382-9631-c44a46f98239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNEK4uNiZXNb",
        "outputId": "37e2e416-9ca2-45e0-d09e-07cd4b6d13e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Launch the Streamlit App with Ngrok\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Install Streamlit to ensure it's available to the current Python environment\n",
        "# We use `sys.executable` to install to the correct Python interpreter.\n",
        "import sys\n",
        "!{sys.executable} -m pip install streamlit\n",
        "\n",
        "# Kill any existing ngrok processes to free up tunnels\n",
        "!killall ngrok\n",
        "\n",
        "# Get your Ngrok authentication token from https://dashboard.ngrok.com/auth/your-authtoken\n",
        "# You must paste your token here or set it as a Colab secret.\n",
        "# In a real project, you would store this securely.\n",
        "!ngrok authtoken 31aOG5rc2eTiMll0szeQJIWrf36_254v194Qn4WdcdQoFdvbr\n",
        "\n",
        "# Start the Streamlit app using subprocess.Popen and capture output\n",
        "process = subprocess.Popen([\"python\", \"-m\", \"streamlit\", \"run\", \"app.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "print(\"Starting Streamlit app... Please wait a moment.\")\n",
        "\n",
        "# Give the app a moment to start up\n",
        "time.sleep(10)\n",
        "\n",
        "# Check for errors from the Streamlit process\n",
        "if process.poll() is not None:\n",
        "    stdout_output, stderr_output = process.communicate()\n",
        "    print(\"Streamlit App has terminated with an error:\")\n",
        "    print(\"--- Standard Output ---\")\n",
        "    print(stdout_output.decode())\n",
        "    print(\"--- Standard Error ---\")\n",
        "    print(stderr_output.decode())\n",
        "else:\n",
        "    # Start the ngrok tunnel\n",
        "    public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "    print(\"Streamlit App URL:\", public_url)\n",
        "\n",
        "    print(\"Streamlit app is running! Click the URL above to access it.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhoVu3EEWqeU",
        "outputId": "be57e5df-e894-495e-eb0a-c892ccb6036b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.48.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Starting Streamlit app... Please wait a moment.\n",
            "Streamlit App URL: NgrokTunnel: \"https://32ecc379643d.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "Streamlit app is running! Click the URL above to access it.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNSOMYd52RsWbD8z7pI3qj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a490f1a39b144a5bad4538dae59bc050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8378e54cbf2b4e25b07fe5d6913396d3",
              "IPY_MODEL_18b8d84f9fc646d1a6dc338c6a40033f",
              "IPY_MODEL_caee5f82c70644768def53fa6c97ef83"
            ],
            "layout": "IPY_MODEL_fd864a7710874f82b7457cdf6bc3fd07"
          }
        },
        "8378e54cbf2b4e25b07fe5d6913396d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545c48a0ac234db18f4e3d2d13ee3851",
            "placeholder": "​",
            "style": "IPY_MODEL_f44a6aa3ec5b4086b1e169011e8f8408",
            "value": "Map: 100%"
          }
        },
        "18b8d84f9fc646d1a6dc338c6a40033f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030c58f182cd4c489ed764ebf167cd14",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60e994e8658343ba8b42fccf9fd1bf8e",
            "value": 2000
          }
        },
        "caee5f82c70644768def53fa6c97ef83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e40615d5aa4c5da93ccb6ba5260e98",
            "placeholder": "​",
            "style": "IPY_MODEL_d20f3d25d2f24e908f0e2407705a062d",
            "value": " 2000/2000 [00:01&lt;00:00, 1301.38 examples/s]"
          }
        },
        "fd864a7710874f82b7457cdf6bc3fd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "545c48a0ac234db18f4e3d2d13ee3851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44a6aa3ec5b4086b1e169011e8f8408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030c58f182cd4c489ed764ebf167cd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e994e8658343ba8b42fccf9fd1bf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5e40615d5aa4c5da93ccb6ba5260e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20f3d25d2f24e908f0e2407705a062d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}